{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c476e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 1, 3: 1, 4: 1}\n",
      "{'this': 1, 'is': 2, 'a': 3, 'test': 4}\n"
     ]
    }
   ],
   "source": [
    "vocab = {}  # maps word to integer representing it\n",
    "word_encoding = 1\n",
    "def bag_of_words(text):\n",
    "  global word_encoding\n",
    "\n",
    "  words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\n",
    "  bag = {}  # stores all of the encodings and their frequency\n",
    "\n",
    "  for word in words:\n",
    "    if word in vocab:\n",
    "      encoding = vocab[word]  # get encoding from vocab\n",
    "    else:\n",
    "      vocab[word] = word_encoding\n",
    "      encoding = word_encoding\n",
    "      word_encoding += 1\n",
    "    \n",
    "    if encoding in bag:\n",
    "      bag[encoding] += 1\n",
    "    else:\n",
    "      bag[encoding] = 1\n",
    "  \n",
    "  return bag\n",
    "\n",
    "text = \"this is a test\"\n",
    "bag = bag_of_words(text)\n",
    "print(bag)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14240b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad8913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 88584\n",
    "max_len = 250\n",
    "batch_size = 64\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "954d9ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd584b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data, max_len)\n",
    "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d037b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7cb1e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "453efad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 86s 136ms/step - loss: 0.4134 - acc: 0.8086 - val_loss: 0.2986 - val_acc: 0.8842\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 81s 129ms/step - loss: 0.2360 - acc: 0.9097 - val_loss: 0.4773 - val_acc: 0.8446\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 75s 121ms/step - loss: 0.1811 - acc: 0.9336 - val_loss: 0.4953 - val_acc: 0.8094\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 75s 121ms/step - loss: 0.1531 - acc: 0.9457 - val_loss: 0.3849 - val_acc: 0.8564\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 76s 122ms/step - loss: 0.1337 - acc: 0.9531 - val_loss: 0.2948 - val_acc: 0.8904\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 75s 120ms/step - loss: 0.1120 - acc: 0.9619 - val_loss: 0.3120 - val_acc: 0.8862\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 72s 115ms/step - loss: 0.0970 - acc: 0.9671 - val_loss: 0.2971 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 73s 118ms/step - loss: 0.0872 - acc: 0.9720 - val_loss: 0.3090 - val_acc: 0.8928\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 72s 115ms/step - loss: 0.0749 - acc: 0.9754 - val_loss: 0.3344 - val_acc: 0.8870\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 72s 116ms/step - loss: 0.0678 - acc: 0.9791 - val_loss: 0.3676 - val_acc: 0.8652\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a8a26b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 40s 51ms/step - loss: 0.4116 - acc: 0.8489\n",
      "[0.4115636646747589, 0.8488799929618835]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9756801",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "def encode_text(text):\n",
    "    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences([tokens], max_len)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46a72d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12  17  13  35 477  40 477]\n"
     ]
    }
   ],
   "source": [
    "text = \"that movie was so amazing, just amazing\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "507e93b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was so amazing just amazing\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = {value:key for (key, value) in word_index.items()}\n",
    "def decode_text(integers):\n",
    "    pad =0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num!=pad:\n",
    "            text += reverse_word_index[num]+\" \"\n",
    "            \n",
    "    return text[:-1]\n",
    "print(decode_text(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2e087a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 229ms/step\n",
      "[0.9694247]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.47167164]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred)\n",
    "    print(result[0])\n",
    "    \n",
    "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
    "predict(negative_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d17dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
